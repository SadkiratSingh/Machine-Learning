# machine-learning
gradient-descent in linear regression
1.https://www.youtube.com/watch?v=vsWrXfO3wWw&t=998s
2.https://www.youtube.com/watch?v=sDv4f4s2SB8
3.https://www.youtube.com/watch?v=jc2IthslyzM
4.https://jermwatt.github.io/machine_learning_refined/notes/3_First_order_methods/3_6_Descent.html

### weakness of gradient descent.
5.https://jermwatt.github.io/machine_learning_refined/notes/9_Feature_engineer_select/9_3_Scaling.html

## feature-scaling
**1.https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff**
2.https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e
3.https://www.geeksforgeeks.org/ml-feature-scaling-part-2/?ref=lbp
4.https://kharshit.github.io/blog/2018/03/23/scaling-vs-normalization#:~:text=Feature%20scaling%20(also%20known%20as,while%20using%20machine%20learning%20algorithms.
**5.https://jermwatt.github.io/machine_learning_refined/notes/9_Feature_engineer_select/9_3_Scaling.html**

#### a standardised data distribution is not a normal data distribution.See here->
5.https://stats.stackexchange.com/questions/141600/some-issues-with-standardized-variable-in-a-regression-analysis
6.https://junkcharts.typepad.com/numbersruleyourworld/2019/11/myth-standardizing-variables-makes-them-normal.html
